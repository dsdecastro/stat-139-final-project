---
title: "Characterizing the relationship between the religious affiliation and incidences of Covid-19 at U.S. universities."
author: "Daniel de Castro and Laura Appleby"
date: "December 13, 2022"
output: pdf_document
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, results=TRUE, messages=FALSE)
```

```{r, eval=T, include=F}
library(dplyr)
library(rpart)
library(rpart.plot)
library(randomForest)
library(modelsummary)
library(sandwich)
library(ggplot2)

library(lemon)
knit_print.data.frame <- lemon_print
```

```{r, eval=T, include=F}
RMSE <- function(y, yhat) {
  SSE = sum((y-yhat)^2)
  return(sqrt(SSE/length(y)))
}
```

# Introduction

Paragraph expressing our motivations for pursuing this project, a brief analysis plan, and our hypotheses. 

# Description of data and source

Our data for this project comes from three sources: 

1. [NYTimes Covid-19 Data](https://github.com/nytimes/covid-19-data/tree/master/colleges). This is publicly available on GitHub and was the source for some of the NYTimes maps and data visuals during the 2020-2021 era of the pandemic. It includes cases from 2020 - May 2021, and we have specifically selected cases at Universities. This dataset has 1948 entries and includes 2020 cases, 2021 cases, University IPEDS ID, University Name, State, etc. 

2. [IPEDS Data Center](https://nces.ed.gov/ipeds/use-the-data). This is publicly available data on colleges across the globe. It has many possible variables including demographics, admission rates, University affiliation, etc. The IPEDS data center allowed us to select certain Universities and variables. The smallest subset of Universities that included all from the NYTimes database (by IPEDS ID) was 6125 rows, with all US Universities. 

3. [Centers for Disease Control](https://data.cdc.gov/Policy-Surveillance/U-S-State-and-Territorial-Public-Mask-Mandates-Fro/tzyy-aayg). This publicly available data set tracks mask mandates in each state from April 8, 2020, to August 15, 2021. 

4. The presidential elections data from STAT 139 Problem Set 4. Of this data set, we will be particularly focused on the `gap20repub` predictor, which we will use to help characterize the political climate of the state in which each institution is located.  

The data has $n = 1,855$ rows after removing Universities without stats or without matching IPEDS ids.

# Data Cleaning Procedures

Our first step in cleaning the data is to read our data from CSV files into R data frames. The `colleges` data frame stores the NYT data on Covid cases at universities, while the `ipeds` data frame stores the data will most of our predictor variables (university characteristics) taken from IPEDS. We then rename most of the columns in `ipeds` to make them shorter and easier to work with. 

```{r, eval=T, echo = FALSE}
# Read colleges from csv
colleges <- read.csv("data/colleges.csv")[,-c(1,9)]

# Read ipeds from csv, drop unnecessary columns
ipeds <- read.csv("data/ipeds.csv")
ipeds <- ipeds[-c(3, 8, 22)]

# Rename columns of ipeds 
ipeds <- ipeds %>% rename_at('IC2021.Institutional.control.or.affiliation', 
                             ~'control') %>% 
                    rename_at('HD2021.FIPS.state.code', ~'FIPS.state.code') %>% 
                    rename_at('unitid', ~'ipeds_id') %>% 
                    rename_at('IC2021.Religious.affiliation', 
                              ~'religious.affiliation') %>%
                    rename_at('DRVIC2021.Tuition.and.fees..2020.21', 
                              ~'tuition') %>% 
                    rename_at('DRVEF122021.Total.12.month.unduplicated.headcount', 
                              ~'total.headcount') %>% 
                    rename_at('DRVEF122021.Undergraduate.12.month.unduplicated.headcount',
                    ~'undergrad.headcount') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.American.Indian.or.Alaska.Native', 
                              ~'percent.american.native') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.Asian', 
                              ~'percent.asian') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.Black.or.African.American', 
                              ~'percent.black') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.Hispanic.Latino', ~'percent.hispanic.latino') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.Native.Hawaiian.or.Other.Pacific.Islander', 
                              ~'percent.pacific.islander') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.White', 
                              ~'percent.white') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.two.or.more.races', 
                              ~'percent.two.more.races') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.race.ethnicity.unknown', ~'percent.NA.race') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.Nonresident.Alien',
                              ~'percent.nonres.alien') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.women', ~'percent.women') %>% 
                    rename_at('SFA2021.Average.amount.of.grant.and.scholarship.aid.awarded..2020.21', ~'avg.grant.money') %>% 
                    rename_at('DRVGR2021.Graduation.rate..total.cohort', ~'grad.rate') %>% 
                    rename_at('SFA2021.Percent.of.full.time.first.time.undergraduates.awarded.any.financial.aid', 
                              ~'percent.fin.aid') %>% 
                    rename_at('SFA2021.Percent.of.full.time.first.time.undergraduates.awarded.student.loans', 
                              ~'percent.student.loan') %>% 
                    rename_at('IC2021.Occupational', ~'occupational.degree') %>% 
                    rename_at('IC2021.Academic', ~'academic.degree') %>% 
                    rename_at('IC2021.Adult.basic.remedial.or.high.school.equivalent', 
                              ~'hs.equivalent.degree') %>% 
                    rename_at('IC2021.Percent.of.undergraduates..who.are.formally.registered.as.students.with.disabilities..when.percentage.is.more.than.3.percent', 
                              ~'percent.disability') %>% 
                    rename_at('IC2021.NCAA.NAIA.conference.number.football', 
                              ~'NCAA.football') %>% 
                    rename_at('IC2021.Institution.provide.on.campus.housing', 
                              ~'on.campus.housing') %>% 
                    rename_at('IC2021.Total.dormitory.capacity', 
                              ~'dorm.capacity') %>% 
                    rename_at('IC2021.Typical.room.charge.for.academic.year', 
                              ~'dorm.room.price')
```

Next, we merge the `colleges` and `ipeds` data frames on the `ipeds_id` column and remove institutions with no IPEDS data. We then create the `religious`, `catholic`, and `private` columns, which are simply indicators for whether an institution has any religious affiliation, whether it has a catholic affiliation, and whether it is a private university. Finally, we drop any unnecessary or redundant columns from the data frame.

```{r, eval=T, echo = FALSE}
# Merge data frames, and remove duplicated "state" column 
md <- merge(ipeds, colleges, by="ipeds_id")[,-32]

# Remove institutions with no ipeds data (a lot of NAs)
md <- md[!(md$control == ""),]

# Create column 'religious' 
md$religious <- "Yes"
md[md$religious.affiliation == "Not applicable", ]$religious <- "No"

# Create column 'catholic'
md$catholic <- "No"
md[md$religious.affiliation == "Roman Catholic",]$catholic <- "Yes"

# Create column 'private' 
md$private <- "No"
md$private[md$control == "Private not-for-profit (no religious affiliation)" | 
             md$control == "Private not-for-profit (religious affiliation)"] <- 
  "Yes"

# Drop column 'control', 'academic.degree', 'dorm.room.price'
md <- md[,-c(4,24,30)]

# Set 'dorm.capacity' to 0 if no on.campus.housing
md$dorm.capacity[md$on.campus.housing == "No"] <- 0

# Write to csv 
write.csv(md,'merged_cases.csv')
```

We then look to add a column to the data frame that addresses the extent to which mask mandates were present in the state in which each institution is located. We read out the mask mandates data from the CDC into a data frame from the CSV file, treat the appropriate columns as factors, and convert `date` into R's `Date` type.  

```{r, eval=T, echo = FALSE}
# Read mask.mandates from CSV file
mask.mandates <- read.csv("data/U.S._State_and_Territorial_Public_Mask_Mandates_From_April_8__2020_through_August_15__2021_by_State_by_Day.csv")

# Convert appropriate columns to factors
factor.variables <- c("Face_Masks_Required_in_Public", "State_Tribe_Territory", "order_code")
mask.mandates[,factor.variables] <- lapply(mask.mandates[,factor.variables], as.factor)

# Convert column 'date' to type Date from string 
mask.mandates$date <- as.Date(mask.mandates$date, format="%m/%d/%Y")
```

The next step is to create a new simpler data frame to merge with `md`. This data frame contains only two columns: One with the name of each state, and the other with the number of days between July 1, 2020, and May 26, 2021, during which face masks were required in public in that state. We then merge this data frame with `md` to create `full.cases`, and create a column `total.cases` in `full.cases` that sums the `cases` and `cases_2021` columns.

```{r, eval=T, echo = FALSE}
# Create new data frame to merge with md
mandates.by.state <- data.frame(state=unique(mask.mandates$State_Tribe_Territory))

# Create and fill column 'mask.mandated.days'
mandates.by.state$mask.mandated.days <- 0
for (i in 1:length(unique(mandates.by.state$state))) {
  dummy <- mask.mandates$Face_Masks_Required_in_Public[mask.mandates$State_Tribe_Territory == mandates.by.state$state[i]
                                                       & mask.mandates$date >= as.Date("2020/7/1")
                                                       & mask.mandates$date <= as.Date("2021/5/26")]
  dummy[is.na(dummy)] <- "No"
  mandates.by.state$mask.mandated.days[mandates.by.state$state == mandates.by.state$state[i]] = sum(dummy == "Yes")
}

# Add state names to mandates.by.state
mandates.by.state$full_state_name <- c("Alaska", "Alabama", "Arkansas", 
                                       "American Samoa", "Arizona", 
                                       "California", "Colorado", 
                                       "District of Columbia", "Connecticut", 
                                       "Florida", "Delaware", "Georgia", "Guam", 
                                       "Iowa", "Hawaii", "Idaho", "Illinois", 
                                       "Indiana", "Kansas", "Kentucky", 
                                       "Louisiana", "Massachusetts", 
                                       "Minnesota", "Maryland", "Maine", 
                                       "Michigan", "Missouri", 
                                       "Northern Mariana Islands", 
                                       "Mississippi", "Montana", 
                                       "North Carolina", "North Dakota", 
                                       "Nebraska", "New Hampshire", "Nevada", 
                                       "New Jersey", "New Mexico", "Ohio", 
                                       "New York", "Oklahoma", "Oregon", 
                                       "South Carolina", "Rhode Island", 
                                       "Pennsylvania", "Puerto Rico", 
                                       "South Dakota", "Tennessee", "Texas", 
                                       "Utah", "Virginia", "Virgin Islands", 
                                       "Vermont", "Washington", "Wisconsin", 
                                       "West Virginia", "Wyoming")

# Drop state abbreviation column and reorder remaining two columns 
mandates.by.state <- mandates.by.state[,c(3,2)]

# Merge md and mandates.by.state data frames on name of state
full.cases <- merge(md, mandates.by.state, by.x="FIPS.state.code", 
      by.y="full_state_name")

# Create total.cases column
full.cases$total.cases <- full.cases$cases + full.cases$cases_2021

# Convert necessary columns to factors 
factor.variables <- c("religious", "FIPS.state.code", "private", 
                      "occupational.degree", 
                      "hs.equivalent.degree", "NCAA.football", 
                      "on.campus.housing", "catholic", "state")
full.cases[,factor.variables] <- lapply(full.cases[,factor.variables], as.factor)
```

Finally, we read the presidential election data from Problem Set 4 into a data frame, create a two-column data frame with the columns `state` and `gap20repub`, and merge this data frame with our data frame of observations on the `state` variable. 

```{r, eval=T}
elections.data <- read.csv("data/pres_elections.csv")
voter.gap <- elections.data[,c("state", "gap20repub")]
voter.gap$state[voter.gap$state == "DC"] <- "Washington, D.C."

full.cases <- merge(full.cases, voter.gap, by="state")
write.csv(full.cases, "full_cases.csv")
```

# Description of variables

After performing the data cleaning procedures outlined above, we are left with the following ADJUST NUMBER! columns:

* **ipeds_id** 

* **institution.name**

* **state**    

* **private**

* **religious.affiliation**

* **religious**

* **catholic**

* **tuition**

* **total.headcount**

* **percent.american.native**

* **percent.asian**

* **percent.black**

* **percent.hispanic.latino** 

* **percent.pacific.islander**

* **percent.white**     

* **percent.two.more.races**

* **percent.NA.race**

* **percent.nonres.alien**

* **percent.women** 

* **avg.grant.money**

* **grad.rate**

* **percent.fin.aid** 

* **percent.student.loan**

* **occupational.degree**

* **hs.equivalent.degree**

* **on.campus.housing** 

* **dorm.capacity**

* **city**

* **college**

* **cases**

* **cases_2021**

* **religious**   

* **catholic**

* **private**

* **mask.mandated.days**

* **total.cases**

* **gap20repub**


# Group Testing

To begin our analyses, we will perform a range of group tests to determine whether the institutions with a religious affiliation had a higher true average number of Covid cases than religious institutions without a religious affiliation. In the following analyses, we will test whether or not the true average number of cases in the fall semester — i.e., the case counts for just 2020 in the NYT data set, `cases` — were different for these two groups of institutions, as well as whether the true average number of cases for the entire academic year —  see the description of `total.cases` — different for the two groups of institutions. We will perform both sets of analyses, because they are so fast and easy to perform and interpret. Later, as we bfit linear models to perform more complicated statistical inference procedures with respect to our data set, we will demonstrate why a focus will be placed on case counts from the fall semester only (see "Determining whether data from 2020 or 2020 and 2021 should be used").

## Checking the assumptions for $t$-based methods

We begin with the most commonly used test for a difference in means: the Student-$t$ test. Of course, before we can perform this test, we must make sure that its underlying assumptions are reasonable. Because we have no reason to assume that the variances in the observations between both groups — religiously affiliated and not religiously affiliated universities — are the same, we will use the unpooled $t$-test. For unpooled $t$-based test for a difference in sample means, there are three assumptions:

1) **Observations are independent.** We claim that this observation is reasonable. Even though the geographic proximity of universities — or just a relationship between universities in which students from one frequently visit the other — might have caused there to be some correlation between case counts at these different schools, we claim that since universities are somewhat insular communities — students tend to stay within their own social sphere of their university —  this is not a major concern. Overall, with such a rich data set, in which a wide and diverse range of characteristics are expressed across all 1,855 observations, this assumption of independence of observations seems reasonable. 

2) **Groups are independent of one another.** There is no reason to suggest that the two groups in question — religious institutions and non-religious institutions — are not independent from one another. Above, we justified that all of the observations in our data set are sufficiently independent from one another — if this is true, there is no reason to suggest that these two groups of religious institutions would not be independent of one another. 

3) **Observations are normally distributed.** As is shown in the plot below (left), both of the response variables in question are *not* normally distributed; after log-transforming these responses, however, we see that their distirbution is symmetrical enough to satisfy this assumption. Of course, we do not need to seek perfect normality with respect to these distributions, since $t$-based statistical inference procedures are robust to this assumption (as was demonstrated in Question 5 in Problem Set 3).

```{r, eval=T}
epsilon <- 1

par(mfrow=c(2,2))
hist(full.cases$cases, main="2020 cases, untransformed", xlab="2020 cases")
hist(log(full.cases$cases + epsilon), main="2020 cases, log-transformed", 
     xlab="2020 cases")
hist(full.cases$total.cases, main="total.cases, untransformed", 
     xlab="total.cases")
hist(log(full.cases$total.cases + epsilon), main="total.cases, log-transformed",
     xlab="total.cases")
```

The Normal Q-Q Plots below corroborate the conclusion that this assumption is reasonable. In each plot, the data for the most part follows the line that we would expect if it were perfectly normally distributed; although, since the data sits below the line at both the positive and negative extremes of the graph, the left tail is a bit fatter and the right tail a bit skinnier than the perfectly normal distribution in each of these sample distributions. 

```{r, eval=T}
par(mfrow=c(1,2))
qqnorm(log(full.cases$cases + epsilon), main="Normal Q-Q Plot, 2020 cases")
qqline(log(full.cases$cases + epsilon))
qqnorm(log(full.cases$total.cases + epsilon), 
       main="Normal Q-Q Plot, total.cases")
qqline(log(full.cases$total.cases + epsilon))
```

## Student-$t$ Tests 

Now that we have shown the assumptions of Student-$t$ tests to be reasonable, we can proceed to perform the test itself. We perform two two-sided $t$-tests for a difference in means. In each case, the null hypothesis is that the true mean case counts in the two groups — religiously affiliated and non-religiously affiliated institutions — are equal over the given time period, and the alternative is that they are not equal. As in the rest of the paper, we will use the standard confidence level of $\alpha = 0.05$, for the sake of convenience and conformity. Below are the results from these tests. 

```{r, eval=T, render=lemon_print}
cases.t.test <- t.test(log(cases + epsilon) ~ religious, data=full.cases)
total.t.test <- t.test(log(total.cases + epsilon) ~ religious, data=full.cases)

data.frame(sample=c("2020 only", "entire year"), 
           test.statistic=c(cases.t.test$statistic, total.t.test$statistic),
           df=c(cases.t.test[[2]], total.t.test[[2]]),
           p.value=c(cases.t.test$p.value, total.t.test$p.value))
```

In both tests, we see that our p-value is greater than the significance level of 0.05; we thus fail to reject the null hypothesis in both cases — we do not have statistically significant evidence to suggest that the true mean case counts, both for the fall semester and for the entire year, are different between the religiously affiliated and non-religiously affiliated institutions. Note that the degrees of freedom — which are not integers owing to R's use of the Welch approximation — are different for the two tests. This is because the test using the `total.cases` data has fewer observations, since some schools in our sample did not report case counts for the spring semester. This issue is tackled in greater detail below (see "Determining whether data from 2020 or 2020 and 2021 should be used"). 

<!--- 

TF Sumhith recommended that we do not anyting based on `religious.affiliation` since there are so many different groups. Better to just focus on `religion`. 

## ANOVA

```{r, eval=T}
for.rel.affil <- full.cases[,c("cases", "religious.affiliation")]
for.rel.affil <- for.rel.affil[complete.cases(for.rel.affil),]
summary(aov(cases ~ religious.affiliation, data=for.rel.affil))
```

Shows that just breaking observations into religious vs. not religious (or catholic vs. not catholic) is much more informative than considering the specific religious affiliation of each school. -->

## Non-Parametric Testing — Wilcox Rank Sum Test

We will also perform the non-parametric Wilcox Rank Sum Test to determine whether the case counts are different between religiously affiliated and non-religiously affiliated schools. The strength of this non-parametric test lies in the fact that it does not rely on a assumption on the distribution of the data-generating process of the sample follows. Thus, though we are confident in having shown above that the distributions of the log-transformed responses are sufficiently approximately normal, for the sake of completeness, we will perform this non-parametric test, and see if it leads us to the same conclusions. 

Again, we will perform the Wilcox Rank Sum Test on data from just the fall semester and on data from the entire academic year. For the following two tests, the null hypothesis is that the true average quantiles within the two groups — when the data from both groups are ranked together — are the same, while the alternative hypothesis is that there is an association between group status and the average quantile of the observations in the entire population. 

```{r, eval=T, render=lemon_print}
cases.wilcox <- wilcox.test(x = full.cases$cases[full.cases$religious == "Yes"], 
            y = full.cases$cases[full.cases$religious == "No"], 
            alternative='two.sided', exact = FALSE, correct = FALSE, 
            conf.int = TRUE)
total.wilcox<-wilcox.test(x=full.cases$total.cases[full.cases$religious=="Yes"], 
            y = full.cases$total.cases[full.cases$religious == "No"], 
            alternative='two.sided', exact = FALSE, correct = FALSE, 
            conf.int = TRUE)

data.frame(sample=c("2020 only", "entire year"), 
           test.statistic=c(cases.wilcox$statistic, total.wilcox$statistic),
           p.value=c(cases.wilcox$p.value, total.wilcox$p.value))
```

As the results above show, neither test was statistically significant at the 0.05 confidence level; we thus again fail to reject the null hypothesis, concluding that there is no statistically significant evidence to suggest that the there is an association between religious affiliation and average quantile of case counts in either sample. 

# Basic Linear Regression Models

Of course, group tests are limited in that they do not take into account potential confounding variables that might reveal the significance of an institution's having a religious affiliation. To take into account the effects of these potential confounding variables — which we have already identified at length, as evidenced by the extensive list of predictors we compiled before beginning our analyses — we will fit linear models. We will then use these linear models to perform statistical inference on the coefficient of the `religious` predictor, determining whether there is a statistically significant relationship between an institution's religious affiliation and the number of cases that it recorded.

## Checking the Assumptions of Linear Regression Models

Before we can fit more complicated models, we must first check the assumptions of linear regression. We begin by checking the assumption of linearity. To do so, we plotted `cases` versus all of the quantitative predictors that we would like to include in our analyses (the complete list of these plots can be found in Appendix A). We the identified that `total.headcount`, `percent.american.native`, `percent.asian`, `percent.black`, `percent.hispanic.latino`, and `percent.pacific.islander` would benefit from being log-transformed; given the left-skewness of its distribution, we also determined that `percent.fin.aid` would be best transformed using the following transformation `log(100 - percent.fin.aid + 1)`. The following plots show that the distribution of these predictors before and after being transformed. *In these plots, the y-axis is always log-transformed cases* (2020); the axis label is not printed in order to save space. 

```{r, eval=T, fig.height=1.5, message=FALSE}
library(patchwork)
suppressWarnings(print((ggplot(full.cases, aes(y=log(cases + epsilon), x=total.headcount)) + geom_point() + ylab("")) + 
  (ggplot(full.cases, aes(y=log(cases + epsilon), x=log(total.headcount))) + geom_point() + ylab(""))))

suppressWarnings(print((ggplot(full.cases, aes(y=log(cases + epsilon), x=percent.american.native)) + geom_point() + ylab("")) + 
  (ggplot(full.cases, aes(y=log(cases + epsilon), x=log(percent.american.native))) + geom_point() + ylab(""))))

suppressWarnings(print((ggplot(full.cases, aes(y=log(cases + epsilon), x=percent.asian)) + geom_point() + ylab("")) + 
  (ggplot(full.cases, aes(y=log(cases + epsilon), x=log(percent.asian))) + geom_point() + ylab(""))))

suppressWarnings(print((ggplot(full.cases, aes(y=log(cases + epsilon), x=percent.black)) + geom_point() + ylab("")) +
  (ggplot(full.cases, aes(y=log(cases + epsilon), x=log(percent.black))) + geom_point() + ylab(""))))

suppressWarnings(print((ggplot(full.cases, aes(y=log(cases + epsilon), x=percent.hispanic.latino)) + geom_point() + ylab("")) + 
  (ggplot(full.cases, aes(y=log(cases + epsilon), x=log(percent.hispanic.latino))) + geom_point() + ylab(""))))

suppressWarnings(print((ggplot(full.cases, aes(y=log(cases + epsilon), x=percent.pacific.islander)) + geom_point() + ylab("")) + 
  (ggplot(full.cases, aes(y=log(cases + epsilon), x=log(percent.pacific.islander))) + geom_point() + ylab(""))))

suppressWarnings(print((ggplot(full.cases, aes(y=log(cases + epsilon), x=percent.fin.aid)) + geom_point() + ylab("")) + 
  (ggplot(full.cases, aes(y=log(cases + epsilon), x=log(100-percent.fin.aid+1))) + geom_point() + ylab(""))))
```

We claim that with these transformations, the assumption of linearity is reasonable. 

What remains to be shown is that the assumption of homoskedasticity is reasonable. In order to check this assumption, we fit basic regression models for `cases` and `total.cases` using all of the predictors in our predictor set.

```{r, eval=T, fig.height=4}
lm6 <- lm(log(cases + epsilon) ~ religious + tuition + 
            log(total.headcount+epsilon) + 
            log(percent.american.native+epsilon) + log(percent.asian+epsilon) + 
            log(percent.black+epsilon) + log(percent.hispanic.latino+epsilon) + 
            log(percent.pacific.islander+epsilon) +
            percent.white + percent.two.more.races + 
            percent.women + grad.rate + log(100-percent.fin.aid+epsilon) + 
            on.campus.housing + gap20repub + 
            private + percent.student.loan + mask.mandated.days +
            occupational.degree + hs.equivalent.degree, data=full.cases)

plot(lm6$residuals ~ lm6$fitted.values, main="cases (2020)", xlab="fitted values",
     ylab="residuals")
abline(h=0, col="gray")
```

As is shown in the plot above, the spread of the residuals is not constant across the entire range of fitted values — thus, it is called into question whether the assumption of homoskedasticity is reasonable in this case. The behavior of this graph is interesting: The lower bound for the residuals appears to follow a negatively sloped line, and one that contains a solid number of points. ADDRESS ASK TF!

Given that the vast majority of residuals are clustered around a region with consistent spread, we believe that the assumption of homoskedasticity will be reasonable enough to accept in this case. As a check, we will compare the standard errors generated by heteroskedasticity-consistent method with those generated by the standard OLS approach: 

```{r, eval=T, render=lemon_print}
vcov.robust = vcovHC(lm6, type="HC")
data.frame(ols=round(summary(lm6)$coef[,'Std. Error'],4), 
           robust=round(sqrt(diag(vcov.robust)),4), 
           "absolute difference"=round(abs(sqrt(diag(vcov.robust)) - 
                            summary(lm6)$coef[,'Std. Error']),4))
```

As the table above shows, the standard errors are the most part consistent between the two models. ADDRESS ASK TF!

```{r, eval=T, fig.height=4}
lm7 <- lm(log(total.cases + epsilon) ~ religious + tuition + 
            log(total.headcount+epsilon) + 
            log(percent.american.native+epsilon) + log(percent.asian+epsilon) + 
            log(percent.black+epsilon) + log(percent.hispanic.latino+epsilon) + 
            log(percent.pacific.islander+epsilon) +
            percent.white + percent.two.more.races + 
            percent.women + grad.rate + log(100-percent.fin.aid+epsilon) + 
            on.campus.housing + gap20repub + 
            private + percent.student.loan + mask.mandated.days +
            occupational.degree + hs.equivalent.degree, data=full.cases)

plot(lm7$residuals ~ lm7$fitted.values, main="total.cases (2020-21)", 
     xlab="fitted values", ylab="residuals")
abline(h=0, col="gray")
```

In the above plot for the model for `total.cases`, the spread of the residuals is much more consistent across the entire range of fitted values. Though it is not entirely uniform, it would appear reasonable enough to operate under the assumption of homoskedasticity, especially given that, as was demonstrated in Problem Set 3, $t$-based statistical inference procedures done using linear models are fairly robust to slight violations in the assumption of homoskedasticity. 

## Determining whether data from 2020 or 2020 and 2021 should be used 

Naturally, there is a temptation to forget about the case data for only 2020 and to focus on case data for the entire academic year (the entire time period during which case data was collected by the *New York Times*). There is one problem, however: While the *New York Times* was able to compile case data for all of the schools in our data set for the fall semester of that year, it was not able to find data for 297 schools for the spring semester. This is a nontrivial number of observations given that our data set only consists of 1855 different institutions; thus, to determine whether it would be sound to remove these 297 observations and fit models and perform statistical inferences on data from the entire academic year, we must determine whether the two groups of schools in question — those that reported data for the entire academic year, and those that did not — are sufficiently similar to one another. 

The first step is to compare the coefficients of our baseline model (`lm6` above) when it is fit to all 1855 observations, as well as individually to the two different groups of schools in question. The coefficient estimates, along with the p-values (not adjusted to be heteroskedastically consistent) are given below.

```{r, eval=T}
lm6.both.only <- lm(formula(lm6), 
                    data=full.cases[!is.na(full.cases$cases_2021),])
lm6.twenty.only <- lm(formula(lm6),
                      data=full.cases[is.na(full.cases$cases_2021),])
modelsummary(list("all schools"=lm6, 
                  "schools with data\nfor both years"=lm6.both.only, 
                  "schools with only\n2020 data"=lm6.twenty.only),
             estimate="{estimate}", 
             statistic="{p.value}",
             shape=term ~ model + statistic)
```

As we can see, when the sample of the institutions used to fit the model changes, some of the coefficient estimates change vastly. Take, for example, the coefficient estimate for `religionYes`, which can be interpreted as the change in cases that we would expect if a given school were to have a religious affiliation rather than not have one. This coefficient estimate is not statistically significant when all institutions are considered together, is positive and statistically significant when the institutions that reported data for the entire academic year are considered, and negative and statistically significant when the institutions that only reported data for the fall are considered. In fact, if one were to inspect the table above, they would notice that the majority of predictors included in this baseline models experienced changes in coefficient estimates and statistical significance as the sample of institutions considered was changed.  

Clearly, then, there are some underlying differences between the schools that did and the schools that did not report case data for the spring semester of the 2020-21 academic year. Consider, the coefficient estimate for `religiousYes`, which represents the change in the number of `cases` that we would expect given that a school were to be religiously affiliated, with all other predictors held constant. The coefficient estimate for `religiousYes` is quite different in the two models fit to data from only one of the two subgroups, which is especially interesting for our research purposes. Indeed, searching for the differences between these subgroups in terms of `religious` and other predictors might help us to answer the questions about the association between religious affiliation and reported Covid cases that are motivating this paper. 

First, we investigate the difference in the political leanings of the states in which these schools were located, as given by `gap20repub`. To do so, we perform a $t$-test (the assumptions that allow us to do so have been explored above), with the null hypothesis being that the true means `gap20repub` are equal between the two groups of institutions, and the alternative being that the true means are different. The result of this test is shown below. 

```{r, eval=T, render=lemon_print}
only.twenty <- full.cases[is.na(full.cases$cases_2021),]
both <- full.cases[!is.na(full.cases$cases_2021),]

gap20.test <- t.test(both$gap20repub, only.twenty$gap20repub)
data.frame(predictor=c("gap20repub"), test.statistic=c(gap20.test$statistic),
           df=c(gap20.test[[2]]),
           p.value=c(gap20.test$p.value))
```

With a p-value that is much smaller than our $\alpha =0.05$ (again, because we do not assume equal variances between the groups, the Welch approximation for degrees of freedom is used), we reject the null hypothesis, concluding that the true mean `gap20repub` is different for the schools that did report case data for 2021 versus those that did not. As it turns out, the 95% $t$-based confidence interval for the mean `gap20repub` for the schools that did report 2021 case data minus the mean `gap20repub` for the schools that did not is (-9.468120, -4.959647) — thus, we conclude that the schools that did report 2021 case data are located in states that are considerably more left-leaning than the schools that did not. 

We repeat this sort of analysis for `total.headcount`, `tuition`, `percent.fin.aid`, `mask.mandated.days`, `on.campus.housing`, and `religious`, predictors that we have chosen based on large differences in the coefficient estimates produced by the models above when fit to only one of the two subgroups of institutions. We use a two-sided $t$-test for the quantitative variables and two-sided z-tests for proportions (ADDRESS) for the `categorical` predictors. The hypotheses are similar to above, the null being that the true means/proportions are equal between the two groups, and the alternative being that they are not equal. As per the results shown below, the tests for all six of these predictors showed statistically significant differences between the two groups of universities. 

```{r, eval=T, render=lemon_print}
size.test <- t.test(both$total.headcount, only.twenty$total.headcount)
tuition.test <- t.test(both$tuition, only.twenty$tuition)
fin.aid.test <- t.test(both$percent.fin.aid, only.twenty$percent.fin.aid)
mask.test <- t.test(both$mask.mandated.days, only.twenty$mask.mandated.days)
on.campus.test <- prop.test(x=matrix(c(sum(both$on.campus.housing == "Yes"), sum(both$on.campus.housing == "No"), 
                     sum(only.twenty$on.campus.housing == "Yes"), 
                     sum(only.twenty$on.campus.housing == "No")), nrow=2, byrow=T), 
          n=c(length(both$on.campus.housing), length(only.twenty$on.campus.housing)))
religious.test <- prop.test(x=matrix(c(sum(both$religious == "Yes"), sum(both$religious == "No"), 
                     sum(only.twenty$religious == "Yes"), 
                     sum(only.twenty$religious == "No")), nrow=2, byrow=T), 
          n=c(length(both$religious), length(only.twenty$religious)))

data.frame(predictor=c("total.headcount", "tuition", "percent.fin.aid",
                       "mask.mandated.days", "on.campus.housing", 
                       "religious"),
           test.statistic=c(size.test$statistic, tuition.test$statistic,
                            fin.aid.test$statistic, mask.test$statistic,
                            on.campus.test$statistic, religious.test$statistic),
           df=c(size.test[[2]], tuition.test[[2]], fin.aid.test[[2]], 
                mask.test[[2]], on.campus.test[[2]], religious.test[[2]]),
           p.value=c(size.test$p.value, tuition.test$p.value, 
                     fin.aid.test$p.value, 
                     mask.test$p.value, on.campus.test$p.value, 
                     religious.test$p.value))
```

The existence of these statistically significant differences between these two groups of institutions leads us to two distinct conclusions: Firstly, that we should perform all further analyses on data only from the fall 2020 semester, and secondly, that we should consider interaction effects in our model to help better isolate and take into account these demonstrated differences between these two different groups of institutions.  

# Linear Models with Interaction Effects

Comments: 
- Assumed use of total.cases - can change
- should we do a polynomial model? not possible with religous but something else?
- What do you think of the explanations? Is there too much here? 

Above we performed several linear regressions with no interactions and multiple predictors. Our "base model" includes all of the predictors we include in this paper, which are: `religious`, `tuition`, `total.headcount`, `percent.american.native`, `percent.asian`, `percent.black`, `percent.hispanic.latino`, `percent.pacific.islander`, `percent.white`, `percent.two.more.races`, `percent.women`, `grad.rate`, `percent.fin.aid`, `on.campus.housing`, `gap20repub`, `private`, `percent.student.loan`, `mask.mandated.days`, `occupational.degree` and `hs.equivelant.degree`. Above we discuss using 2020 cases, 2021 cases, or the total number of cases, concluding that we will use only 2020 cases for the remaining models. 

We will now look at interaction effects and their significance in linear regression models for this dataset. First, we will look at a model with fewer predictors; including only `religious`, `total.headcount`, `grad.rate`, `percent.fin.aid`, `dorm.capacity`, and `gap20repub` to predict 2020 cases. We chose these variables because we anticipate there to not be a high degree of multicollinearity between them, and because they were statistically significant in predicting 2020 cases in a simple linear regression above. See `lm8` for the model with no interaction effects, `lm9` for interaction effects with the `religious` variables, and `lm10` for the all interaction effects between the variables in `lm8`: 

```{r}

lm8 <- lm(log(cases + epsilon) ~ religious + log(total.headcount+epsilon) + 
            + percent.fin.aid + log(dorm.capacity+epsilon) + gap20repub, 
          data = full.cases)
            
summary(lm8)

lm9 <- lm(log(cases + epsilon) ~ (log(total.headcount+epsilon) + 
            + percent.fin.aid + log(dorm.capacity+epsilon) + gap20repub)*religious, 
          data = full.cases)

summary(lm9)


lm10 <- lm(log(cases + epsilon) ~ (religious + log(total.headcount+epsilon) + 
            + percent.fin.aid + log(dorm.capacity+epsilon) + gap20repub)^2, 
          data = full.cases)

summary(lm10)

```
We see from the model without interaction effects that all chosen variables are statistically significant in predicting total cases in this specific model. Notably, the coefficient on `religiousYes` is positive and statistically significant, indicating that a school being religious predicts a higher number of cases than a non-religious institution. The interaction model with the variables from the previous models and their interactions with the religious variable has a slightly higher r-squared value than the model without interactions; `r summary(lm9)$r.squared`, versus `r summary(lm8)$r.squared`. 

There was only one interaction effect that was statistically significant, that between `gap20repub` and `religious`. Even though `gap20repub` has a statistically significant positive effect when predicting cases across models when keeping `religious` constant (as one might expect; institutions in more republican states likely had fewer COVID-19 precautions, resulting in disproportionately higher cases), the relationship between `gap20repub` and `total.cases` is not quite as strong for institutions that are religious (though the coefficient is close to 0). This is statistically significant, with the negative interaction effect coefficient having a p-value of $0.00155$, which is significantly below the level $\alpha = 0.05$. 

Only one statistically significant interaction effect explains why the $R^2$ value for the `religious` interaction model was not a lot greater than that for the no interaction model. Conversely, the $R^2$ for the full interaction effect model (with these few selected variables) is a significant amount greater, with value `r summary(lm10)$r.squared`. 

```{r}
# ESS F-test
anova(lm8, lm9)

# ESS F-test
anova(lm8, lm10)
```

From the ESS F-test, we see that there is evidence that the `religious` interaction terms contribute to the model. More significantly, there is evidence that the other interaction terms in the third model contribute even more significantly. This indicates that though `religious` has some interaction with the confounding variables, these predictors interact with one another more significantly.

```{r}
religYes = (full.cases$religious == "Yes")

plot(cases[religYes == TRUE] ~ gap20repub[religYes == TRUE],
     data = full.cases,
     pch = 21, cex = 1.2, col=rgb(0,0.1,1,0.8),
     ylab = "total cases",xlab = "gap20repub",
     xlim = c(-90, 50), ylim = c(0,2000))
points(full.cases$gap20repub[religYes == FALSE], 
       full.cases$cases[religYes == FALSE],
       pch = 21,cex = 1.2,  col=rgb(1,0.1,0,0.3))

abline(a = lm9$coef[1], b = lm9$coef[5], lty = 1, col = "royalblue4",
lwd = 2)
abline(a = lm9$coef[1]+lm9$coef[6], b = lm9$coef[5]+lm9$coef[10], lty = 2, col = "red",
lwd = 2)

```

The above plot confirms that adding the interaction between `religious` and the other selected variables, though statistically significant for the variable `gap20repub`, does not change the model significantly. This is clear because the two predictive lines are nearly identical. They are low compared visually to the data due to the high number of 0 cases.

We will next look at a full interaction model with all variables as used in the base linear regression model, as well as their interaction with only religious. We will simply compare $R^2$, p-values, and RMSE to determine the importance of interaction in the models. 

```{r}
lm7 <- lm(log(total.cases + epsilon) ~ religious + tuition + 
            log(total.headcount+epsilon) + 
            log(percent.american.native+epsilon) + log(percent.asian+epsilon) + 
            log(percent.black+epsilon) + log(percent.hispanic.latino+epsilon) + 
            log(percent.pacific.islander+epsilon) +
            percent.white + percent.two.more.races + 
            percent.women + grad.rate + log(100-percent.fin.aid+epsilon) + 
            on.campus.housing + gap20repub + 
            private + percent.student.loan + mask.mandated.days +
            occupational.degree + hs.equivalent.degree, data=full.cases)

summary(lm7)$r.squared

religiousInteraction <- lm(log(cases + epsilon) ~ religious*( tuition + 
            log(total.headcount+epsilon) + 
            log(percent.american.native+epsilon) + log(percent.asian+epsilon) + 
            log(percent.black+epsilon) + log(percent.hispanic.latino+epsilon) + 
            log(percent.pacific.islander+epsilon) +
            percent.white + percent.two.more.races + 
            percent.women + grad.rate + log(100-percent.fin.aid+epsilon) + 
            on.campus.housing + gap20repub + 
            private + percent.student.loan + mask.mandated.days +
            occupational.degree + hs.equivalent.degree), data=full.cases)

summary(religiousInteraction)$r.squared
#summary(religiousInteraction)

fullInteraction <- lm(log(cases + epsilon) ~ (religious + tuition + 
            log(total.headcount+epsilon) + 
            log(percent.american.native+epsilon) + log(percent.asian+epsilon) + 
            log(percent.black+epsilon) + log(percent.hispanic.latino+epsilon) + 
            log(percent.pacific.islander+epsilon) +
            percent.white + percent.two.more.races + 
            percent.women + grad.rate + log(100-percent.fin.aid+epsilon) + 
            on.campus.housing + gap20repub + 
            private + percent.student.loan + mask.mandated.days +
            occupational.degree + hs.equivalent.degree)^2, data=full.cases)

summary(fullInteraction)$r.squared
#summary(fullInteraction)

RMSE <- function(y, yhat) {
     SSE = sum(na.omit(y-yhat)^2)
     return(sqrt(SSE/length(y)))
}

# getting errors so maybe don't use?
RMSE(full.cases$cases, predict(lm6, full.cases))
RMSE(full.cases$cases, predict(lm8, full.cases))
RMSE(full.cases$cases, predict(lm9, full.cases))


anova(lm6, religiousInteraction)

anova(religiousInteraction, fullInteraction)

# ESS F-test
anova(lm8, lm10)

```
- Talk a couple p-values

- From the ESS F-test, we can see that the interaction terms with just religious contribute to the model. Furthermore, the full interaction terms contribute in addition to the just religious terms. 

- conclude this section? there is a huge weight with interaction terms, but religious does not interact with other variables as much as they interact with one another. 

# In Search of a Parsimonious Model: Sequential Variable Selection Models

```{r, eval=F}
df = full.cases[,c("gap20repub", "mask.mandated.days", "private","tuition","total.headcount","undergrad.headcount","percent.american.native","percent.asian","percent.black","percent.hispanic.latino","percent.pacific.islander","percent.white","percent.two.more.races","percent.NA.race","percent.nonres.alien","percent.women","grad.rate","percent.fin.aid","percent.student.loan","NCAA.football","percent.disability","on.campus.housing","religious","total.cases")] 
# I think we should drop NCAA.football as a predictor from our set 
# With so many NA values, we also pretty much have to drop percent.disability

df = na.omit(df)

summary(model1 <- lm(log(total.cases+epsilon) ~ mask.mandated.days + private+tuition+total.headcount+undergrad.headcount+percent.american.native+percent.asian+ percent.black+percent.hispanic.latino+percent.pacific.islander+percent.white+percent.two.more.races+percent.NA.race+percent.nonres.alien+percent.women           +grad.rate+percent.fin.aid+percent.student.loan+NCAA.football+percent.disability+on.campus.housing+religious, data = df))


interactionModel <- lm(log(total.cases+epsilon) ~ (mask.mandated.days+ private+tuition+total.headcount+undergrad.headcount+percent.american.native+percent.asian+ percent.black+percent.hispanic.latino+percent.pacific.islander+percent.white+percent.two.more.races+percent.NA.race+percent.nonres.alien+percent.women +grad.rate+percent.fin.aid+percent.student.loan+NCAA.football+percent.disability+on.campus.housing+religious)^2, data = df)


back.step <- step(model1, direction = "backward", k = 2)

## including states, excluding days mandated:
# removed columns are control, undergrad.headcount, percent.pacific.islander,on.campus.housing

## including days mandated, excluding states:
# removed columns are control, percent.american.native + percent.two.more.races+percent.NA.race,on.campus.housing+percent.disability

#forward.step = step(model1, scope = list(upper = formula(interactionModel)), direction = "forward")

#model0 = lm(log(percent.cases+1) ~ 1, full.cases)

#step = step(model1, scope = list(lower = formula(model0), upper = formula(interactionModel)),
#direction = "both")
```

Honestly not sure how to interpret and forward step model and the both-directions step model take forever to run. 

# LASSO for Variable Section

# Hierarchical Multi-level Models

# Conclusions


# Appendix A: Plots to Check the Assumption of Linearity

```{r, eval=T}
par(mfrow=c(3,2), mar=1.5 * c(1,1,1,1), cex=0.5)
plot(log(total.cases + epsilon) ~ tuition, data=full.cases,
     main="tuition")
plot(log(total.cases + epsilon) ~ total.headcount, data=full.cases,
     main="total.headcount")
plot(log(total.cases + epsilon) ~ percent.american.native, data=full.cases,
     main="percent.american.native")
plot(log(total.cases + epsilon) ~ percent.asian, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.black, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.hispanic.latino, data=full.cases)
par(mfrow=c(3,2), mar=2 * c(1,1,1,1), cex=0.5)
plot(log(total.cases + epsilon) ~ percent.pacific.islander, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.white, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.two.more.races, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.women, data=full.cases)
plot(log(total.cases + epsilon) ~ grad.rate, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.fin.aid, data=full.cases)
par(mfrow=c(3,2), mar=2 * c(1,1,1,1), cex=0.5)
plot(log(total.cases + epsilon) ~ gap20repub, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.student.loan, data=full.cases)
plot(log(total.cases + epsilon) ~ mask.mandated.days, data=full.cases)
```


# Laura's work from before

```{r, eval=F}
# Not included in the below model: NCAA.football, religious.affiliation, 
# mask.mandated days, as well as those subtracted from the formula of
# the commented out lm1 below

#full.cases$percent.cases <- full.cases$total.cases/full.cases$total.headcount

summary(lm1 <- lm(log(total.cases + epsilon) ~ religious + catholic + 
            tuition + total.headcount + 
            undergrad.headcount + percent.american.native + percent.asian + 
            percent.black + percent.hispanic.latino + percent.pacific.islander +
            percent.white + percent.two.more.races + percent.NA.race + 
            percent.nonres.alien + percent.women + grad.rate + percent.fin.aid + 
            percent.disability + on.campus.housing + state + 
            private + percent.student.loan + 
            occupational.degree + hs.equivalent.degree, 
          data=full.cases))

summary(lm2 <- lm(log(total.cases + epsilon) ~ religious + private + tuition, full.cases))

summary(lm3 <-lm(log(total.cases+epsilon)~(religious + tuition + percent.white+percent.black+mask.mandated.days)^2,full.cases))

full.cases.tuit = full.cases[complete.cases(full.cases[,c("tuition")]),]

lm5 = lm(total.cases ~ poly(tuition, 3, raw=TRUE), data = full.cases.tuit)
summary(lm5)

x=500:61500
yhat = predict(lm5,new=data.frame(tuition=x))

plot(total.cases~tuition,data=full.cases.tuit)
lines(yhat~x,col="magenta",lwd=4)

df = full.cases

# avg.grant.money, dorm.capacity, dorm.room.price, academic.degree
```
