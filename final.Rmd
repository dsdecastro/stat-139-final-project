---
title: "Characterizing the relationship between the religious affiliation and incidences of Covid-19 at U.S. universities."
author: "Daniel de Castro and Laura Appleby"
date: "December 13, 2022"
output: pdf_document
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, results=TRUE, messages=FALSE)
```

```{r, eval=T, include=F}
library(dplyr)
library(rpart)
library(rpart.plot)
library(randomForest)
library(sandwich)
library(modelsummary)
library(report)
# library(rempsync)
```

```{r, eval=T, include=F}
RMSE <- function(y, yhat) {
  SSE = sum((y-yhat)^2)
  return(sqrt(SSE/length(y)))
}
```

# Introduction

Paragraph expressing our motivations for pursuing this project, a brief analysis plan, and our hypotheses. 

# Description of data and source

Our data for this project comes from three sources: 

1. [NYTimes Covid-19 Data](https://github.com/nytimes/covid-19-data/tree/master/colleges). This is publicly available on GitHub and was the source for some of the NYTimes maps and data visuals during the 2020-2021 era of the pandemic. It includes cases from 2020 - May 2021, and we have specifically selected cases at Universities. This dataset has 1948 entries and includes 2020 cases, 2021 cases, University IPEDS ID, University Name, State, etc. 

2. [IPEDS Data Center](https://nces.ed.gov/ipeds/use-the-data). This is publicly available data on colleges across the globe. It has many possible variables including demographics, admission rates, University affiliation, etc. The IPEDS data center allowed us to select certain Universities and variables. The smallest subset of Universities that included all from the NYTimes database (by IPEDS ID) was 6125 rows, with all US Universities. 

3. [Centers for Disease Control](https://data.cdc.gov/Policy-Surveillance/U-S-State-and-Territorial-Public-Mask-Mandates-Fro/tzyy-aayg). This publicly available data set tracks mask mandates in each state from April 8, 2020, to August 15, 2021. 

4. The presidential elections data from STAT 139 Problem Set 4. Of this data set, we will be particularly focused on the `gap20repub` predictor, which we will use to help characterize the political climate of the state in which each institution is located.  

The data has $n = 1,855$ rows after removing Universities without stats or without matching IPEDS ids.

# Data Cleaning Procedures

Our first step in cleaning the data is to read our data from CSV files into R data frames. The `colleges` data frame stores the NYT data on Covid cases at universities, while the `ipeds` data frame stores the data will most of our predictor variables (university characteristics) taken from IPEDS. We then rename most of the columns in `ipeds` to make them shorter and easier to work with. 

```{r, eval=T, echo = FALSE}
# Read colleges from csv
colleges <- read.csv("data/colleges.csv")[,-c(1,9)]

# Read ipeds from csv, drop unnecessary columns
ipeds <- read.csv("data/ipeds.csv")
ipeds <- ipeds[-c(3, 8, 22)]

# Rename columns of ipeds 
ipeds <- ipeds %>% rename_at('IC2021.Institutional.control.or.affiliation', 
                             ~'control') %>% 
                    rename_at('HD2021.FIPS.state.code', ~'FIPS.state.code') %>% 
                    rename_at('unitid', ~'ipeds_id') %>% 
                    rename_at('IC2021.Religious.affiliation', 
                              ~'religious.affiliation') %>%
                    rename_at('DRVIC2021.Tuition.and.fees..2020.21', 
                              ~'tuition') %>% 
                    rename_at('DRVEF122021.Total.12.month.unduplicated.headcount', 
                              ~'total.headcount') %>% 
                    rename_at('DRVEF122021.Undergraduate.12.month.unduplicated.headcount',
                    ~'undergrad.headcount') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.American.Indian.or.Alaska.Native', 
                              ~'percent.american.native') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.Asian', 
                              ~'percent.asian') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.Black.or.African.American', 
                              ~'percent.black') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.Hispanic.Latino', ~'percent.hispanic.latino') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.Native.Hawaiian.or.Other.Pacific.Islander', 
                              ~'percent.pacific.islander') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.White', 
                              ~'percent.white') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.two.or.more.races', 
                              ~'percent.two.more.races') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.race.ethnicity.unknown', ~'percent.NA.race') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.Nonresident.Alien',
                              ~'percent.nonres.alien') %>% 
                    rename_at('DRVEF122021.Percent.of.12.month.unduplicated.headcount.that.are.women', ~'percent.women') %>% 
                    rename_at('SFA2021.Average.amount.of.grant.and.scholarship.aid.awarded..2020.21', ~'avg.grant.money') %>% 
                    rename_at('DRVGR2021.Graduation.rate..total.cohort', ~'grad.rate') %>% 
                    rename_at('SFA2021.Percent.of.full.time.first.time.undergraduates.awarded.any.financial.aid', 
                              ~'percent.fin.aid') %>% 
                    rename_at('SFA2021.Percent.of.full.time.first.time.undergraduates.awarded.student.loans', 
                              ~'percent.student.loan') %>% 
                    rename_at('IC2021.Occupational', ~'occupational.degree') %>% 
                    rename_at('IC2021.Academic', ~'academic.degree') %>% 
                    rename_at('IC2021.Adult.basic.remedial.or.high.school.equivalent', 
                              ~'hs.equivalent.degree') %>% 
                    rename_at('IC2021.Percent.of.undergraduates..who.are.formally.registered.as.students.with.disabilities..when.percentage.is.more.than.3.percent', 
                              ~'percent.disability') %>% 
                    rename_at('IC2021.NCAA.NAIA.conference.number.football', 
                              ~'NCAA.football') %>% 
                    rename_at('IC2021.Institution.provide.on.campus.housing', 
                              ~'on.campus.housing') %>% 
                    rename_at('IC2021.Total.dormitory.capacity', 
                              ~'dorm.capacity') %>% 
                    rename_at('IC2021.Typical.room.charge.for.academic.year', 
                              ~'dorm.room.price')
```

Next, we merge the `colleges` and `ipeds` data frames on the `ipeds_id` column and remove institutions with no IPEDS data. We then create the `religious`, `catholic`, and `private` columns, which are simply indicators for whether an institution has any religious affiliation, whether it has a catholic affiliation, and whether it is a private university. Finally, we drop any unnecessary or redundant columns from the data frame.

```{r, eval=T, echo = FALSE}
# Merge data frames, and remove duplicated "state" column 
md <- merge(ipeds, colleges, by="ipeds_id")[,-32]

# Remove institutions with no ipeds data (a lot of NAs)
md <- md[!(md$control == ""),]

# Create column 'religious' 
md$religious <- "Yes"
md[md$religious.affiliation == "Not applicable", ]$religious <- "No"

# Create column 'catholic'
md$catholic <- "No"
md[md$religious.affiliation == "Roman Catholic",]$catholic <- "Yes"

# Create column 'private' 
md$private <- "No"
md$private[md$control == "Private not-for-profit (no religious affiliation)" | 
             md$control == "Private not-for-profit (religious affiliation)"] <- 
  "Yes"

# Drop column 'control', 'academic.degree', 'dorm.room.price'
md <- md[,-c(4,24,30)]

# Set 'dorm.capacity' to 0 if no on.campus.housing
md$dorm.capacity[md$on.campus.housing == "No"] <- 0

# Write to csv 
write.csv(md,'merged_cases.csv')
```

We then look to add a column to the data frame that addresses the extent to which mask mandates were present in the state in which each institution is located. We read out the mask mandates data from the CDC into a data frame from the CSV file, treat the appropriate columns as factors, and convert `date` into R's `Date` type.  

```{r, eval=T, echo = FALSE}
# Read mask.mandates from CSV file
mask.mandates <- read.csv("data/U.S._State_and_Territorial_Public_Mask_Mandates_From_April_8__2020_through_August_15__2021_by_State_by_Day.csv")

# Convert appropriate columns to factors
factor.variables <- c("Face_Masks_Required_in_Public", "State_Tribe_Territory", "order_code")
mask.mandates[,factor.variables] <- lapply(mask.mandates[,factor.variables], as.factor)

# Convert column 'date' to type Date from string 
mask.mandates$date <- as.Date(mask.mandates$date, format="%m/%d/%Y")
```

The next step is to create a new simpler data frame to merge with `md`. This data frame contains only two columns: One with the name of each state, and the other with the number of days between July 1, 2020, and May 26, 2021, during which face masks were required in public in that state. We then merge this data frame with `md` to create `full.cases`, and create a column `total.cases` in `full.cases` that sums the `cases` and `cases_2021` columns.

```{r, eval=T, echo = FALSE}
# Create new data frame to merge with md
mandates.by.state <- data.frame(state=unique(mask.mandates$State_Tribe_Territory))

# Create and fill column 'mask.mandated.days'
mandates.by.state$mask.mandated.days <- 0
for (i in 1:length(unique(mandates.by.state$state))) {
  dummy <- mask.mandates$Face_Masks_Required_in_Public[mask.mandates$State_Tribe_Territory == mandates.by.state$state[i]
                                                       & mask.mandates$date >= as.Date("2020/7/1")
                                                       & mask.mandates$date <= as.Date("2021/5/26")]
  dummy[is.na(dummy)] <- "No"
  mandates.by.state$mask.mandated.days[mandates.by.state$state == mandates.by.state$state[i]] = sum(dummy == "Yes")
}

# Add state names to mandates.by.state
mandates.by.state$full_state_name <- c("Alaska", "Alabama", "Arkansas", 
                                       "American Samoa", "Arizona", 
                                       "California", "Colorado", 
                                       "District of Columbia", "Connecticut", 
                                       "Florida", "Delaware", "Georgia", "Guam", 
                                       "Iowa", "Hawaii", "Idaho", "Illinois", 
                                       "Indiana", "Kansas", "Kentucky", 
                                       "Louisiana", "Massachusetts", 
                                       "Minnesota", "Maryland", "Maine", 
                                       "Michigan", "Missouri", 
                                       "Northern Mariana Islands", 
                                       "Mississippi", "Montana", 
                                       "North Carolina", "North Dakota", 
                                       "Nebraska", "New Hampshire", "Nevada", 
                                       "New Jersey", "New Mexico", "Ohio", 
                                       "New York", "Oklahoma", "Oregon", 
                                       "South Carolina", "Rhode Island", 
                                       "Pennsylvania", "Puerto Rico", 
                                       "South Dakota", "Tennessee", "Texas", 
                                       "Utah", "Virginia", "Virgin Islands", 
                                       "Vermont", "Washington", "Wisconsin", 
                                       "West Virginia", "Wyoming")

# Drop state abbreviation column and reorder remaining two columns 
mandates.by.state <- mandates.by.state[,c(3,2)]

# Merge md and mandates.by.state data frames on name of state
full.cases <- merge(md, mandates.by.state, by.x="FIPS.state.code", 
      by.y="full_state_name")

# Create total.cases column
full.cases$total.cases <- full.cases$cases + full.cases$cases_2021

# Convert necessary columns to factors 
factor.variables <- c("religious", "FIPS.state.code", "private", 
                      "occupational.degree", 
                      "hs.equivalent.degree", "NCAA.football", 
                      "on.campus.housing", "catholic", "state")
full.cases[,factor.variables] <- lapply(full.cases[,factor.variables], as.factor)
```

Finally, we read the presidential election data from Problem Set 4 into a data frame, create a two-column data frame with the columns `state` and `gap20repub`, and merge this data frame with our data frame of observations on the `state` variable. 

```{r, eval=T}
elections.data <- read.csv("data/pres_elections.csv")
voter.gap <- elections.data[,c("state", "gap20repub")]
voter.gap$state[voter.gap$state == "DC"] <- "Washington, D.C."

full.cases <- merge(full.cases, voter.gap, by="state")
write.csv(full.cases, "full_cases.csv")
```

# Description of variables

After performing the data cleaning procedures outlined above, we are left with the following ADJUST NUMBER! columns:

* **ipeds_id** 

* **institution.name**

* **state**    

* **private**

* **religious.affiliation**

* **religious**

* **catholic**

* **tuition**

* **total.headcount**

* **percent.american.native**

* **percent.asian**

* **percent.black**

* **percent.hispanic.latino** 

* **percent.pacific.islander**

* **percent.white**     

* **percent.two.more.races**

* **percent.NA.race**

* **percent.nonres.alien**

* **percent.women** 

* **avg.grant.money**

* **grad.rate**

* **percent.fin.aid** 

* **percent.student.loan**

* **occupational.degree**

* **hs.equivalent.degree**

* **NCAA.football**

* **percent.disability**

* **on.campus.housing** 

* **dorm.capacity**

* **city**

* **college**

* **cases**

* **cases_2021**

* **religious**   

* **catholic**

* **private**

* **mask.mandated.days**

* **total.cases**

* **gap20repub**


# Group Testing

Explain motivation for group testing

## Checking the assumptions for $t$-based methods

For unpooled $t$-based test for a difference in sample means, there are three assumptions:

1) **Observations are independent.** Explain why reasonable. 

2) **Groups are independent of one another.** Explain why reasonable. 

3) **Observations are normally distributed.** 

```{r, eval=T}
epsilon <- 1

par(mfrow=c(1,2))
hist(full.cases$total.cases, main="total.cases, untransformed")
hist(log(full.cases$total.cases + epsilon), main="total.cases, log-transformed")
```

```{r, eval=T}
qqnorm(log(full.cases$total.cases + epsilon))
qqline(log(full.cases$total.cases + epsilon))
```

## Student-$t$ Tests 

State hypotheses, add note confirming the use of $\alpha = 0.05$ as our confidence level throughout the paper. 

```{r, eval=T}
t.test(log(total.cases + epsilon) ~ religious, data=full.cases)
```

Interpret statistical significance

## ANOVA

```{r, eval=T}
for.rel.affil <- full.cases[,c("total.cases", "religious.affiliation")]
for.rel.affil <- for.rel.affil[complete.cases(for.rel.affil),]
summary(aov(total.cases ~ religious.affiliation, data=for.rel.affil))
```

Shows that just breaking observations into religious vs. not religious (or catholic vs. not catholic) is much more informative than considering the specific religious affiliation of each school. 

## Non-Parametric Testing — Wilcox Rank Sum Test

Motivations for non-parametric testing, and hypotheses 

```{r, eval=T}
wilcox.test(x = full.cases$total.cases[full.cases$religious == "Yes"], 
            y = full.cases$total.cases[full.cases$religious == "No"], 
            alternative='two.sided', exact = FALSE, correct = FALSE, 
            conf.int = TRUE)
```

Interpret significance 

# Basic Linear Regression Models

Of course, group tests are limited in that they do not take into account potential confounding variables that might reveal the significance of an institution's having a religious affiliation. To take into account the effects of these potential confounding variables — which we have already identified at length, as evidenced by the extensive list of predictors we compiled before beginning our analyses — we will fit linear models. We will then use these linear models to perform statistical inference on the coefficient of the `religious` predictor, determining whether there is a statistically significant relationship between an institution's religious affiliation and the number of cases that it recorded.

## Checking the Assumptions of Linear Regression Models

Before we can fit more complicated models, we must first check the assumptions of linear regression. We begin by checking the assumption of linearity, plotting `cases` versus all of the quantitative predictors that we would like to include in our analyses: 

```{r, eval=T}
par(mfrow=c(3,2), mar=1.5 * c(1,1,1,1), cex=0.5)
plot(log(total.cases + epsilon) ~ tuition, data=full.cases,
     main="tuition")
plot(log(total.cases + epsilon) ~ total.headcount, data=full.cases,
     main="total.headcount")
plot(log(total.cases + epsilon) ~ percent.american.native, data=full.cases,
     main="percent.american.native")
plot(log(total.cases + epsilon) ~ percent.asian, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.black, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.hispanic.latino, data=full.cases)
par(mfrow=c(3,2), mar=2 * c(1,1,1,1), cex=0.5)
plot(log(total.cases + epsilon) ~ percent.pacific.islander, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.white, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.two.more.races, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.women, data=full.cases)
plot(log(total.cases + epsilon) ~ grad.rate, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.fin.aid, data=full.cases)
par(mfrow=c(3,2), mar=2 * c(1,1,1,1), cex=0.5)
plot(log(total.cases + epsilon) ~ gap20repub, data=full.cases)
plot(log(total.cases + epsilon) ~ percent.student.loan, data=full.cases)
plot(log(total.cases + epsilon) ~ mask.mandated.days, data=full.cases)
```

We identify that `total.headcount`, `percent.american.native`, `percent.asian`, `percent.black`, `percent.hispanic.latino`, and `percent.pacific.islander` would benefit from being log-transformed; given the left-skewness of its distribution, we also determined that `percent.fin.aid` would be best transformed using the following transformation `log(100 - percent.fin.aid + 1)`. The following plots show that the distribution of these predictors are much better after being transformed. 

```{r, eval=T}
par(mfrow=c(4,2), mar=c(1,1,1,1))
plot(log(total.cases + epsilon) ~ log(total.headcount), data=full.cases)
plot(log(total.cases + epsilon) ~ log(percent.american.native), data=full.cases)
plot(log(total.cases + epsilon) ~ log(percent.asian), data=full.cases)
plot(log(total.cases + epsilon) ~ log(percent.black), data=full.cases)
plot(log(total.cases + epsilon) ~ log(percent.hispanic.latino), data=full.cases)
plot(log(total.cases + epsilon) ~ log(percent.pacific.islander), data=full.cases)
plot(log(total.cases + epsilon) ~ log(100-percent.fin.aid+1), data=full.cases)
```

After these transformations, the linearity assumptions seems much more reasonable for each of the quantitative predictors. 

In order to check the assumption of homoskedasticity, we fit basic regression models for `cases` and `total.cases` using all of the predictors in our predictor set.

```{r, eval=T}
lm6 <- lm(log(cases + epsilon) ~ religious + tuition + 
            log(total.headcount+epsilon) + 
            log(percent.american.native+epsilon) + log(percent.asian+epsilon) + 
            log(percent.black+epsilon) + log(percent.hispanic.latino+epsilon) + 
            log(percent.pacific.islander+epsilon) +
            percent.white + percent.two.more.races + 
            percent.women + grad.rate + log(100-percent.fin.aid+epsilon) + 
            on.campus.housing + gap20repub + 
            private + percent.student.loan + mask.mandated.days +
            occupational.degree + hs.equivalent.degree, data=full.cases)

plot(lm6$residuals ~ lm6$fitted.values, main="cases")
abline(h=0, col="gray")
```

As is shown in the plot above, the spread of the residuals is not constant across the entire range of fitted values — thus, it is called into question whether the assumption of homoskedasticity is reasonable in this case. Given that the vast majority of residuals are clustered around a region with consistent spread, we believe that the assumption of homoskedasticity will be reasonable enough to accept in this case. As a check, we will compare the standard errors generated by heteroskedasticity-consistent method with those generated by the standard OLS approach: 

```{r, eval=T}
vcov.robust = vcovHC(lm6, type="HC")
data.frame(ols=round(summary(lm6)$coef[,'Std. Error'],4), 
           robust=round(sqrt(diag(vcov.robust)),4), 
           diff=round(abs(sqrt(diag(vcov.robust)) - 
                            summary(lm6)$coef[,'Std. Error']),4))
```

As the table above shows, the standard errors are the most part consistent between the two models. ADDRESS ASK TF!

```{r, eval=T}
lm7 <- lm(log(total.cases + epsilon) ~ religious + tuition + 
            log(total.headcount+epsilon) + 
            log(percent.american.native+epsilon) + log(percent.asian+epsilon) + 
            log(percent.black+epsilon) + log(percent.hispanic.latino+epsilon) + 
            log(percent.pacific.islander+epsilon) +
            percent.white + percent.two.more.races + 
            percent.women + grad.rate + log(100-percent.fin.aid+epsilon) + 
            on.campus.housing + gap20repub + 
            private + percent.student.loan + mask.mandated.days +
            occupational.degree + hs.equivalent.degree, data=full.cases)

plot(lm7$residuals ~ lm7$fitted.values, main="total.cases")
abline(h=0, col="gray")
```

In the above plot for the model for `total.cases`, the spread of the residuals is much more consistent across the entire range of fitted values. Though it is not entirely uniform, it would appear reasonable enough to operate under the assumption of homoskedasticity, especially given that, as was demonstrated in Problem Set 3, $t$-based statistical inference procedures done using linear models are fairly robust to slight violations in the assumption of homoskedasticity. 

## Determining if data from 2020 or 2020 and 2021 should be used 

Naturally, there is a temptation to forget about the case data for only 2020 and to focus on case data for the entire academic year (the entire time period during which case data was collected by the *New York Times*). There is one problem, however: While the *New York Times* was able to compile case data for all of the schools in our data set for the fall semester of that year, it was not able to find data for 297 schools for the spring semester. This is a nontrivial number of observations given that our data set only consists of 1855 different institutions; thus, to determine whether it would be sound to remove these 297 observations and fit models and perform statistical inferences on data from the entire academic year, we must determine whether the two groups of schools in question — those that reported data for the entire academic year, and those that did not — are sufficiently similar to one another. 

The first step is to compare the coefficients of our baseline model (`lm6` above) when it is fit to all 1855 observations, as well as individually to the two different groups of schools in question. The coefficient estimates, along with the p-values (not adjusted to be heteroskedastically consistent) are given below.

```{r, eval=T}
lm6.both.only <- lm(formula(lm6), 
                    data=full.cases[!is.na(full.cases$cases_2021),])
lm6.twenty.only <- lm(formula(lm6),
                      data=full.cases[is.na(full.cases$cases_2021),])
modelsummary(list("all schools"=lm6, 
                  "schools with data\nfor both years"=lm6.both.only, 
                  "schools with only\n2020 data"=lm6.twenty.only),
             estimate="{estimate}", 
             statistic="{p.value}",
             shape=term ~ model + statistic)
```

As we can see, when the sample of the institutions used to fit the model changes, some of the coefficient estimates change vastly. Take, for example, the coefficient estimate for `religionYes`, which can be interpreted as the change in cases that we would expect if a given school were to have a religious affiliation rather than not have one. This coefficient estimate is not statistically significant when all institutions are considered together, is positive and statistically significant when the institutions that reported data for the entire academic year are considered, and negative and statistically significant when the institutions that only reported data for the fall are considered. In fact, if one were to inspect the table above, they would notice that the majority of predictors included in this baseline models experienced changes in coefficient estimates and statistical significance as the sample of institutions considered was changed.  

Let's find out more about the schools that only reported data for 2020: 

```{r, eval=T}
only.twenty <- full.cases[is.na(full.cases$cases_2021),]
both <- full.cases[!is.na(full.cases$cases_2021),]
  
table(only.twenty$religious)
table(only.twenty$private)
hist(only.twenty$total.headcount)
hist(only.twenty$gap20repub)
```

t-test for difference in political leanings
```{r, eval=T}
t.test(both$gap20repub, only.twenty$gap20repub)
```
t-test for difference in size 
```{r, eval=T}
t.test(both$total.headcount, only.twenty$total.headcount)
```

z-test for proportion private
```{r, eval=T}
prop.test(x=matrix(c(sum(both$private == "Yes"), sum(both$private == "No"), 
                     sum(only.twenty$private == "Yes"), 
                     sum(only.twenty$private == "No")), nrow=2, byrow=T), 
          n=c(length(both$private), length(only.twenty$private)))
```

z-test for `religious`
```{r, eval=T}
prop.test(x=matrix(c(sum(both$religious == "Yes"), sum(both$religious == "No"), 
                     sum(only.twenty$religious == "Yes"), 
                     sum(only.twenty$religious == "No")), nrow=2, byrow=T), 
          n=c(length(both$religious), length(only.twenty$religious)))
```

z-test for `on.campus.housing`
```{r, eval=T}
prop.test(x=matrix(c(sum(both$on.campus.housing == "Yes"), sum(both$on.campus.housing == "No"), 
                     sum(only.twenty$on.campus.housing == "Yes"), 
                     sum(only.twenty$on.campus.housing == "No")), nrow=2, byrow=T), 
          n=c(length(both$on.campus.housing), length(only.twenty$on.campus.housing)))
```

THE TWO SAMPLES OF SCHOOLS ARE CLEARLY DIFFERNET WITH RESPECT TO CERTAIN PREDICTORS — INTERACTION EFFECTS MIGHT BE AT PLAY. WE SHOULD RESTRICT SAMPLE TO CASES IN 2020, AND EXPLORE INTERACTION EFFECTS

# Linear Models with Interaction Effects

Comments: 
- Assumed use of total.cases - can change
- should we do a polynomial model? not possible with religous but something else?
- What do you think of the explanations? Is there too much here? 

Above we performed several linear regressions with no interactions and multiple predictors. Our "base model" includes all of the predictors we include in this paper, which are: `religious`, `tuition`, `total.headcount`, `percent.american.native`, `percent.asian`, `percent.black`, `percent.hispanic.latino`, `percent.pacific.islander`, `percent.white`, `percent.two.more.races`, `percent.women`, `grad.rate`, `percent.fin.aid`, `on.campus.housing`, `gap20repub`, `private`, `percent.student.loan`, `mask.mandated.days`, `occupational.degree` and `hs.equivelant.degree`. Above we discuss using 2020 cases, 2021 cases, or the total number of cases, concluding that we will use total cases for the remaining models. 

We will now look at interaction effects and their significance in linear regression models for this dataset. First, we will look at a model with fewer predictors; including only `religious`, `total.headcount`, `grad.rate`, `percent.fin.aid`, `dorm.capacity`, and `gap20repub` to predict 2020 cases. We chose these variables because they are all different from one another and were statistically significant in predicting 2020 cases in a simple linear regression above. See `lm8` for the model with no interaction effects, `lm9` for interaction effects with the `religious` variables, and `lm10` for the all interaction effects between the variables in `lm8`: 

```{r}

lm8 <- lm(log(total.cases + epsilon) ~ religious + log(total.headcount+epsilon) + 
            + percent.fin.aid + log(dorm.capacity+epsilon) + gap20repub, 
          data = full.cases)
            
summary(lm8)

lm9 <- lm(log(total.cases + epsilon) ~ (log(total.headcount+epsilon) + 
            + percent.fin.aid + log(dorm.capacity+epsilon) + gap20repub)*religious, 
          data = full.cases)

summary(lm9)


lm10 <- lm(log(total.cases + epsilon) ~ (religious + log(total.headcount+epsilon) + 
            + percent.fin.aid + log(dorm.capacity+epsilon) + gap20repub)^2, 
          data = full.cases)

summary(lm10)

```
We see from the model without interaction effects that all chosen variables are statistically significant in predicting total cases in this specific model. Notably, the coefficient on "religiousYes" is positive and statistically significant, indicating that a school being religious predicts a higher number of cases than a non-religious institution. The interaction model with the variables from the previous models and their interactions with the religious variable has a slightly higher r-squared value than the model without interactions; `r summary(lm9)$r.squared`, versus `r summary(lm8)$r.squared`. 

There was only one interaction effect that was statistically significant, that between `gap20repub` and `religious`. Even though `gap20repub` has a statistically significant positive effect when predicting cases across models when keeping `religious` constant (as one might expect; institutions in more republican states likely had fewer COVID-19 precautions, resulting in disproportionately higher cases), the relationship between `gap20repub` and `total.cases` is not quite as strong for institutions that are religious (though the coefficient is close to 0). This is statistically significant, with the negative interaction effect coefficient having a p-value of $0.00155$, which is significantly below the level $\alpha = 0.05$. 

Only one statistically significant interaction effect explains why the $R^2$ value for the `religious` interaction model was not a lot greater than that for the no interaction model. Conversely, the $R^2$ for the full interaction effect model (with these few selected variables) is a significant amount greater, with value `r summary(lm10)$r.squared`. 

```{r}
# ESS F-test
anova(lm8, lm9)

# ESS F-test
anova(lm8, lm10)
```

From the ESS F-test, we see that there is evidence that the `religious` interaction terms contribute to the model. More significantly, there is evidence that the other interaction terms in the third model contribute even more significantly. This indicates that though `religious` has some interaction with the confounding variables, these predictors interact with one another more significantly.

```{r}
religYes = (full.cases$religious == "Yes")

plot(total.cases[religYes == TRUE] ~ gap20repub[religYes == TRUE],
     data = full.cases,
     pch = 21, cex = 1.2, col=rgb(0,0.1,1,0.8),
     ylab = "total cases",xlab = "gap20repub",
     xlim = c(-90, 50), ylim = c(0,2000))
points(full.cases$gap20repub[religYes == FALSE], 
       full.cases$total.cases[religYes == FALSE],
       pch = 21,cex = 1.2,  col=rgb(1,0.1,0,0.3))

abline(a = lm9$coef[1], b = lm9$coef[5], lty = 2, col = "royalblue4",
lwd = 2)
abline(a = lm9$coef[1]+lm9$coef[6], b = lm9$coef[5]+lm9$coef[10], lty = 2, col = "red",
lwd = 2)

```

The above plot confirms that adding the interaction between `religious` and the other selected variables, though statistically significant for the variable `gap20repub`, does not change the model significantly. This is clear because the two predictive lines are nearly identical. They are low compared visually to the data due to the high number of 0 cases.

We will next look at a full interaction model with all variables as used in the base linear regression model, as well as their interaction with only religious. We will simply compare $R^2$, p-values, and RMSE to determine the importance of interaction in the models. 

```{r}
lm7 <- lm(log(total.cases + epsilon) ~ religious + tuition + 
            log(total.headcount+epsilon) + 
            log(percent.american.native+epsilon) + log(percent.asian+epsilon) + 
            log(percent.black+epsilon) + log(percent.hispanic.latino+epsilon) + 
            log(percent.pacific.islander+epsilon) +
            percent.white + percent.two.more.races + 
            percent.women + grad.rate + log(100-percent.fin.aid+epsilon) + 
            on.campus.housing + gap20repub + 
            private + percent.student.loan + mask.mandated.days +
            occupational.degree + hs.equivalent.degree, data=full.cases)

summary(lm7)$r.squared

religiousInteraction <- lm(log(total.cases + epsilon) ~ religious *( tuition + 
            log(total.headcount+epsilon) + 
            log(percent.american.native+epsilon) + log(percent.asian+epsilon) + 
            log(percent.black+epsilon) + log(percent.hispanic.latino+epsilon) + 
            log(percent.pacific.islander+epsilon) +
            percent.white + percent.two.more.races + 
            percent.women + grad.rate + log(100-percent.fin.aid+epsilon) + 
            on.campus.housing + gap20repub + 
            private + percent.student.loan + mask.mandated.days +
            occupational.degree + hs.equivalent.degree), data=full.cases)

summary(religiousInteraction)$r.squared
#summary(religiousInteraction)

fullInteraction <- lm(log(total.cases + epsilon) ~ (religious + tuition + 
            log(total.headcount+epsilon) + 
            log(percent.american.native+epsilon) + log(percent.asian+epsilon) + 
            log(percent.black+epsilon) + log(percent.hispanic.latino+epsilon) + 
            log(percent.pacific.islander+epsilon) +
            percent.white + percent.two.more.races + 
            percent.women + grad.rate + log(100-percent.fin.aid+epsilon) + 
            on.campus.housing + gap20repub + 
            private + percent.student.loan + mask.mandated.days +
            occupational.degree + hs.equivalent.degree)^2, data=full.cases)

summary(fullInteraction)$r.squared
#summary(fullInteraction)

RMSE <- function(y, yhat) {
     SSE = sum(na.omit(y-yhat)^2)
     return(sqrt(SSE/length(y)))
}

# getting errors so maybe don't use?
RMSE(full.cases$total.cases, predict(lm7, full.cases))
RMSE(full.cases$total.cases, predict(lm8, full.cases))
RMSE(full.cases$total.cases, predict(lm9, full.cases))


anova(lm7, religiousInteraction)

anova(religiousInteraction, fullInteraction)

# ESS F-test
anova(lm8, lm10)

```
- Talk a couple p-values

- From the ESS F-test, we can see that the interaction terms with just religious contribute to the model. Furthermore, the full interaction terms contribute in addition to the just religious terms. 

- conclude this section? there is a huge weight with interaction terms, but religious does not interact with other variables as much as they interact with one another. 

# In Search of a Parsimonious Model: Sequential Variable Selection Models

```{r, eval=F}
df = full.cases[,c("gap20repub", "mask.mandated.days", "private","tuition","total.headcount","undergrad.headcount","percent.american.native","percent.asian","percent.black","percent.hispanic.latino","percent.pacific.islander","percent.white","percent.two.more.races","percent.NA.race","percent.nonres.alien","percent.women","grad.rate","percent.fin.aid","percent.student.loan","NCAA.football","percent.disability","on.campus.housing","religious","total.cases")]

df = na.omit(df)

summary(model1 <- lm(log(total.cases+epsilon) ~ mask.mandated.days + private+tuition+total.headcount+undergrad.headcount+percent.american.native+percent.asian+ percent.black+percent.hispanic.latino+percent.pacific.islander+percent.white+percent.two.more.races+percent.NA.race+percent.nonres.alien+percent.women           +grad.rate+percent.fin.aid+percent.student.loan+NCAA.football+percent.disability+on.campus.housing+religious, data = df))


interactionModel <- lm(log(total.cases+epsilon) ~ (mask.mandated.days+ private+tuition+total.headcount+undergrad.headcount+percent.american.native+percent.asian+ percent.black+percent.hispanic.latino+percent.pacific.islander+percent.white+percent.two.more.races+percent.NA.race+percent.nonres.alien+percent.women +grad.rate+percent.fin.aid+percent.student.loan+NCAA.football+percent.disability+on.campus.housing+religious)^2, data = df)


back.step <- step(model1, direction = "backward", k = 2)

## including states, excluding days mandated:
# removed columns are control, undergrad.headcount, percent.pacific.islander,on.campus.housing

## including days mandated, excluding states:
# removed columns are control, percent.american.native + percent.two.more.races+percent.NA.race,on.campus.housing+percent.disability

#forward.step = step(model1, scope = list(upper = formula(interactionModel)), direction = "forward")

#model0 = lm(log(percent.cases+1) ~ 1, full.cases)

#step = step(model1, scope = list(lower = formula(model0), upper = formula(interactionModel)),
#direction = "both")
```

Honestly not sure how to interpret and forward step model and the both-directions step model take forever to run. 

# LASSO for Variable Section

# Hierarchical Multi-level Models

# Conclusions



# Laura's work from before

```{r, eval=F}
# Not included in the below model: NCAA.football, religious.affiliation, 
# mask.mandated days, as well as those subtracted from the formula of
# the commented out lm1 below

#full.cases$percent.cases <- full.cases$total.cases/full.cases$total.headcount

summary(lm1 <- lm(log(total.cases + epsilon) ~ religious + catholic + 
            tuition + total.headcount + 
            undergrad.headcount + percent.american.native + percent.asian + 
            percent.black + percent.hispanic.latino + percent.pacific.islander +
            percent.white + percent.two.more.races + percent.NA.race + 
            percent.nonres.alien + percent.women + grad.rate + percent.fin.aid + 
            percent.disability + on.campus.housing + state + 
            private + percent.student.loan + 
            occupational.degree + hs.equivalent.degree, 
          data=full.cases))

summary(lm2 <- lm(log(total.cases + epsilon) ~ religious + private + tuition, full.cases))

summary(lm3 <-lm(log(total.cases+epsilon)~(religious + tuition + percent.white+percent.black+mask.mandated.days)^2,full.cases))

full.cases.tuit = full.cases[complete.cases(full.cases[,c("tuition")]),]

lm5 = lm(total.cases ~ poly(tuition, 3, raw=TRUE), data = full.cases.tuit)
summary(lm5)

x=500:61500
yhat = predict(lm5,new=data.frame(tuition=x))

plot(total.cases~tuition,data=full.cases.tuit)
lines(yhat~x,col="magenta",lwd=4)

df = full.cases

# avg.grant.money, dorm.capacity, dorm.room.price, academic.degree
```
